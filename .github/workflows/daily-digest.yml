name: NBA Pressers Daily Digest

on:
  schedule:
    - cron: '30 9 * * *'
  
  workflow_dispatch:
    inputs:
      hours_back:
        description: 'Hours back to search for videos'
        required: false
        default: '24'
      max_clips:
        description: 'Maximum clips to include'
        required: false
        default: '12'

jobs:
  generate-digest:
    runs-on: self-hosted
    timeout-minutes: 60
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Verify dependencies
        run: |
          Write-Host "=== Python version ==="
          python --version
          Write-Host "=== Checking yt-dlp ==="
          yt-dlp --version
          Write-Host "=== Checking ffmpeg ==="
          ffmpeg -version | Select-Object -First 1
        shell: powershell
        continue-on-error: true
      
      - name: Install Python dependencies
        run: |
          pip install --upgrade yt-dlp feedparser youtube-transcript-api anthropic groq google-api-python-client tweepy requests python-dateutil
        shell: powershell
      
      - name: Create output directories
        run: |
          New-Item -ItemType Directory -Force -Path data
          New-Item -ItemType Directory -Force -Path output\clips
        shell: powershell
      
      - name: Stage 1 - Ingest new videos
        run: |
          cd scripts
          python ingest.py --hours ${{ github.event.inputs.hours_back || '24' }} --output ..\data\videos.json
        shell: powershell
      
      - name: Stage 2 - Fetch transcripts
        run: |
          cd scripts
          python transcribe.py --input ..\data\videos.json --output ..\data\transcripts.json
        shell: powershell
      
      - name: Stage 3 - Score moments
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
        run: |
          cd scripts
          python score_moments.py --input ..\data\transcripts.json --output ..\data\moments.json --top ${{ github.event.inputs.max_clips || '12' }}
        shell: powershell
      
      - name: Stage 4 - Download and process clips
        run: |
          cd scripts
          python clip_videos.py --input ..\data\moments.json --output-dir ..\output\clips --max-clips ${{ github.event.inputs.max_clips || '12' }}
        shell: powershell
        continue-on-error: true
      
      - name: Stage 5 - Compile digest video
        run: |
          cd scripts
          python compile_digest.py --input ..\output\clips\processed_clips.json --output ..\output\digest.mp4
        shell: powershell
        continue-on-error: true
      
      - name: Stage 6 - Run QA checks
        id: qa
        run: |
          cd scripts
          python qa_checks.py --clips ..\output\clips\processed_clips.json --video ..\output\digest.mp4 --output ..\output\qa_report.txt
        shell: powershell
        continue-on-error: true
      
      - name: Upload artifacts for review
        uses: actions/upload-artifact@v4
        with:
          name: digest-${{ github.run_id }}
          path: |
            output/digest.mp4
            output/digest_metadata.json
            output/qa_report.txt
            output/clips/processed_clips.json
            data/
          retention-days: 7
        continue-on-error: true
      
      - name: Notify on failure
        if: failure()
        run: |
          Write-Host "::error::Digest generation failed. Check the logs for details."
        shell: powershell
